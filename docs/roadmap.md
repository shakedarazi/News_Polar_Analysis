ğŸ“˜ RFC â€“ News Analysis Pipeline
×“×˜×¨××™× ×™×¡×˜×™, ××—×§×¨×™, Batch-Oriented (×¢×“ BigQuery)
1ï¸âƒ£ ××˜×¨×ª ×”××¢×¨×›×ª

×œ×‘× ×•×ª ××¢×¨×›×ª ×“×˜×¨××™× ×™×¡×˜×™×ª, ×™×¦×™×‘×” ×•×œ× ×ª×œ×•×™×” ×‘×”×ª× ×”×’×•×ª ××ª×¨×™ ×—×“×©×•×ª, ×©××‘×¦×¢×ª:

××™×¡×•×£ ×›×ª×‘×•×ª ×—×“×©×•×ª ×××¨×›×–×™ ×”×—×“×©×•×ª ×‘×™×©×¨××œ

××™×¡×•×£ ×ª×’×•×‘×•×ª ×§×”×œ ×œ×›×ª×‘×•×ª

× ×™×ª×•×— ×˜×§×¡×˜×•××œ×™ ××‘×•×¡×¡ ××™×œ×•× ×™× (lexicon-based)

×”×¤×§×ª ××“×“×™× ×›××•×ª×™×™× ×œ×—×œ×•× ×•×ª (××©×¤×˜×™×) ×•×œ×ª×’×•×‘×•×ª

×˜×¢×™× ×” × ×§×™×™×” ×œÖ¾BigQuery ×œ×¦×•×¨×š × ×™×ª×•×—×™× ×¢×ª×™×“×™×™×

â—ï¸×”××¢×¨×›×ª ××™× ×” Streaming, ×•××™× ×” × ×•×¢×“×” ×œ×–××ŸÖ¾×××ª.
×”××˜×¨×” ×”×™× ×“×™×•×§, ×™×¦×™×‘×•×ª ×•××—×§×¨×™×•×ª, ×œ× latency.

2ï¸âƒ£ ××§×•×¨×•×ª × ×ª×•× ×™× (Sources)

×”××¢×¨×›×ª ×ª×•××›×ª ×‘××¨×›×–×™ ×”×—×“×©×•×ª ×”××¨×›×–×™×™× ×‘×™×©×¨××œ, ×›×•×œ×œ:

×”××¨×¥

ynet

mako / ×§×©×ª 12

×—×“×©×•×ª 12

×¨×©×ª 13 (×¢×¨×•×¥ 10 ×œ×©×¢×‘×¨)

×¢×¨×•×¥ 14

××§×•×¨×•×ª ×—×“×©×•×ª ××¨×›×–×™×™× × ×•×¡×¤×™× ×‘××•×ª×• ××‘× ×”

â—ï¸×”× ×—×ª ×™×¡×•×“:
××™×Ÿ ×“×¨×š ×××™× ×” ×œ××©×•×š â€œ×›×œ ×›×ª×‘×•×ª ×”×™×•×â€ ×™×©×™×¨×•×ª ××”××ª×¨×™× (feeds ××•×’×‘×œ×™×, ×“×™× ××™×§×” ××©×ª× ×”).

3ï¸âƒ£ ×¢×§×¨×•× ×•×ª ×¢×œ (Design Principles)
3.1 ×“×˜×¨××™× ×™×–×

××•×ª×• input â‡’ ××•×ª×• output

××™×Ÿ ××œ×’×•×¨×™×ª××™× ×œ× ×“×˜×¨××™× ×™×¡×˜×™×™× ×‘Ö¾critical path

×›×œ ×©×™× ×•×™ ×‘Ö¾lexicon / ××œ×’×•×¨×™×ª× â‡’ version ×—×“×©

3.2 Idempotency

×¨×™×¦×•×ª ×—×•×–×¨×•×ª ×œ× ××™×™×¦×¨×•×ª ×›×¤×™×œ×•×™×•×ª

×˜×¢×™× ×” ×œÖ¾BQ × ×¢×©×™×ª ×¨×§ ×“×¨×š staging â†’ MERGE

×›×œ ×™×©×•×ª ××–×•×”×” ×¢"×™ ××¤×ª×— ×—×“Ö¾××©××¢×™

3.3 Separation of Concerns

××™×¡×•×£ (ingestion) ××•×¤×¨×“ ××¢×™×‘×•×“

×ª×’×•×‘×•×ª ××•×¤×¨×“×•×ª ××›×ª×‘×•×ª

LLM ××•×¤×¨×“ ×›Ö¾enrichment ××•×¤×¦×™×•× ×œ×™

3.4 Batch-Oriented

××™×Ÿ ×¦×•×¨×š ×‘Ö¾streaming

×ª×’×•×‘×•×ª × ××“×“×•×ª ×œ××—×¨ ×”×¦×˜×‘×¨×•×ª (24 ×©×¢×•×ª)

4ï¸âƒ£ ××¨×›×™×˜×§×˜×•×¨×” ×›×œ×œ×™×ª (High-Level)

×”××¢×¨×›×ª ×‘× ×•×™×” ××©× ×™ DAGs ×‘Ö¾Airflow:

DAG 1 â€“ Ingestion (×›×œ 6 ×©×¢×•×ª)

××˜×¨×ª×•:

â€œ×œ×”×§×¤×™×â€ ×›×ª×‘×•×ª ×œ×¤× ×™ ×©×”××ª×¨ ××©× ×”/××¢×œ×™× ××•×ª×Ÿ.

DAG 2 â€“ Daily Snapshot + Processing (×™×•××™)

××˜×¨×ª×•:

×œ××¡×•×£ ×ª×’×•×‘×•×ª ×œ××—×¨ ×”×¦×˜×‘×¨×•×ª ×•×œ×—×©×‘ ××“×“×™× ×™×¦×™×‘×™×.

5ï¸âƒ£ ×–×™×”×•×™ ×•×™×©×•×™×•×ª (IDs & Keys)
5.1 canonical_url

× ×™×§×•×™ URL (tracking params, trailing slash, scheme)

5.2 article_id
article_id = sha256(canonical_url)

5.3 ×—×œ×•× ×•×ª ×›×ª×‘×”

×—×œ×•×Ÿ = ××©×¤×˜

sentence_idx = ××™× ×“×§×¡ ×œ××—×¨ sentence split ×“×˜×¨××™× ×™×¡×˜×™

××¤×ª×—: (article_id, sentence_idx)

5.4 ×ª×’×•×‘×•×ª

×× ×™×© comment_id ××”××§×•×¨ â€” ××©×ª××©×™× ×‘×•

××—×¨×ª:

comment_id = sha256(article_id + text + local_index)


××¤×ª×—: (article_id, comment_id)

6ï¸âƒ£ × ×¨××•×œ ×•×˜×§×¡×˜ (Text Processing Spec)
6.1 Normalization (×›×ª×‘×•×ª + ×ª×’×•×‘×•×ª)

×”×¡×¨×ª URLs

×”×¡×¨×ª × ×™×§×•×“

× ×¨××•×œ ×’×¨×©×™×™× / ××§×¤×™×

lowercasing

× ×™×§×•×™ ×ª×•×•×™× ×œ×Ö¾×œ×©×•× ×™×™×

whitespace normalization

â—ï¸×œ× ××‘×¦×¢×™× ×©×™× ×•×™ ×¡×× ×˜×™ ×‘×˜×§×¡×˜.

7ï¸âƒ£ ×—×œ×•×§×” ×œ×—×œ×•× ×•×ª (Article Windows)
×”×—×œ×˜×” × ×¢×•×œ×”:

×—×œ×•×Ÿ = ××©×¤×˜

sentence splitter rule-based ×“×˜×¨××™× ×™×¡×˜×™

×¤×™×¦×•×œ ×œ×¤×™ . ! ? â€¦ ×¢× heuristics ×œ×§×™×¦×•×¨×™× × ×¤×•×¦×™×

×—×¨×™×’:

×× ××©×¤×˜ > 60 ×˜×•×§× ×™×

××¤×•×¦×œ ×œ×ª×ªÖ¾×—×œ×•× ×•×ª ×©×œ 60 ×˜×•×§× ×™×

×”××™× ×“×•×§×¡ (sentence_idx) ×××©×™×š ×‘×¨×¦×£

×”× ××§×” ××—×§×¨×™×ª:

××©×¤×˜ = ×™×—×™×“×ª ×˜×™×¢×•×Ÿ ×˜×‘×¢×™×ª

×××¤×©×¨ ××“×™×“×ª â€œ×¢×•×©×¨ ×§×˜×’×•×¨×™×•×ªâ€ ×•Ö¾dominance

chunking ××•× ×¢ outliers

8ï¸âƒ£ ××¡×˜×¨×˜×’×™×™×ª Lexicon (× ×¢×•×œ)
×”×‘×—×™×¨×” ×”×¨×©××™×ª â€“ ×’×™×©×” A: Expanded Lexicon
×¢×™×§×¨×•×Ÿ

×œ× ××©× ×™× ×˜×•×§× ×™× ×‘×–××Ÿ ×¨×™×¦×”

×”×”×ª×××” ××ª×‘×¦×¢×ª ×¢"×™ ××™×œ×•×Ÿ ××•×¨×—×‘ ××¨××©

lexicon_expanded ×›×•×œ×œ:

××™×œ×” ×‘×¡×™×¡×™×ª

×•×¨×™××¦×™×•×ª ×¢× ×ª×—×™×œ×™×•×ª ×¢×‘×¨×™×•×ª × ×¤×•×¦×•×ª:

×”, ×•, ×‘, ×œ, ×, ×›, ×©

(×©××¨× ×™) ×¦×™×¨×•×£ ×©×›×™×— ×××•×“ ×©×œ ×©×ª×™ ×ª×—×™×œ×™×•×ª ×‘×œ×‘×“ (×œ××©×œ ×•×”)

×œ× ××™×™×¦×¨×™× ×•×¨×™××¦×™×•×ª ×× ××•×¨×š < 3

Versioning

lexicon_base.json

lexicon_expanded.json

lexicon_version = sha256(lexicon_expanded.json)

××•×ª×• ×¢×™×§×¨×•×Ÿ ×œÖ¾×ª×’×•×‘×•×ª:

comment_lexicon_expanded

comment_lexicon_version

××•×¤×¦×™×” ×¢×ª×™×“×™×ª ×‘×œ×‘×“ (×œ× ×‘Ö¾baseline)

×’×™×©×” B: Prefix stripping ×©××¨× ×™

××•×–×›×¨×ª ×›Ö¾Future Work ×‘×œ×‘×“

××™× ×” ××•×¤×¢×œ×ª ×‘×¤×•×¢×œ

9ï¸âƒ£ ××œ×’×•×¨×™×ª× × ×™×ª×•×— ×›×ª×‘×•×ª (7 ×§×˜×’×•×¨×™×•×ª)
Precompute

×™×¦×™×¨×ª word2category (dict)

×œ×›×œ ×—×œ×•×Ÿ:

counts[7]

active = ××¡×¤×¨ ×§×˜×’×•×¨×™×•×ª ×©×•× ×•×ª

window_len

cat_words = sum(counts)

Dominance
dominance = max(counts) / cat_words


×× cat_words == 0 â†’ NULL

×¡×™×‘×•×›×™×•×ª

O(total_tokens_in_article)

ğŸ”Ÿ × ×™×ª×•×— ×ª×’×•×‘×•×ª (Audience Signal)
×ª×’×•×‘×” = ×—×œ×•×Ÿ
×œ×›×œ ×ª×’×•×‘×”:

polar_count

comment_len

polar_ratio = polar_count / max(1, comment_len)

like_weight = 1 + ln(1 + like_count)

comment_score = polar_ratio

×¦×‘×™×¨×” ×‘×¨××ª ×›×ª×‘×”:

num_comments

audience_mean (×××•×¦×¢ ××©×•×§×œ×œ)

audience_p85 (quantile ××©×•×§×œ×œ)

â—ï¸××™×Ÿ ×–×™×”×•×™ ×›×•×ª×‘, ××™×Ÿ ×–××Ÿ ×¤×¨×¡×•× â€” ×‘×›×•×•× ×” (×¤×©×˜×•×ª ×•× ×™×§×™×•×Ÿ).

1ï¸âƒ£1ï¸âƒ£ ××—×¡×•×Ÿ ×‘Ö¾GCS
Raw Articles (DAG 1)
gs://bucket/raw/articles/source=.../dt=YYYY-MM-DD/article_id=.../article.json

Snapshot ×¢× ×ª×’×•×‘×•×ª (DAG 2)
gs://bucket/snapshot/articles_with_comments/source=.../dt=YYYY-MM-DD/article_id=.../article_with_comments.json


×ª×’×•×‘×•×ª ×××™×•× ×•×ª ×œ×¤×™ comment_id â†’ ×“×˜×¨××™× ×™×–×.

1ï¸âƒ£2ï¸âƒ£ Staging Format
×”×—×œ×˜×” × ×¢×•×œ×”:

Parquet

×”× ××§×”:

schema ×—×–×§

columnar

×˜×¢×™× ×” ×™×¢×™×œ×” ×œÖ¾BigQuery

×¤×—×•×ª ×–×™×”×•× × ×ª×•× ×™×

1ï¸âƒ£3ï¸âƒ£ BigQuery â€“ ×˜×‘×œ××•×ª ×™×¢×“

articles

windows_features

comments_features

article_comments_agg

article_llm_enrichment (××•×¤×¦×™×•× ×œ×™)

×›×œ ×˜×¢×™× ×”:

staging â†’ MERGE

×œ×¤×™ ××¤×ª×—×•×ª ×™×™×—×•×“×™×™×

1ï¸âƒ£4ï¸âƒ£ Airflow DAGs
DAG 1 â€“ crawl_latest_to_gcs

×ª×–××•×Ÿ: ×›×œ 6 ×©×¢×•×ª

×ª×¤×§×™×“: ××™×¡×•×£ ×•×”×§×¤××ª ×›×ª×‘×•×ª

DAG 2 â€“ daily_snapshot_process_to_bq

×ª×–××•×Ÿ: ×¤×¢× ×‘×™×•×

×‘×•×—×¨ ×›×ª×‘×•×ª ×©Ö¾now - first_seen_at >= 24h

××•×¡×£ ×ª×’×•×‘×•×ª

××—×©×‘ ×¤×™×¦â€™×¨×™×

×˜×•×¢×Ÿ ×œÖ¾BQ

Concurrency:

×‘×¨××ª ×›×ª×‘×” ×‘×œ×‘×“ (worker pool)

1ï¸âƒ£5ï¸âƒ£ Data Quality (DQ)

window_len > 0

sum(c1..c7) â‰¤ window_len

dominance âˆˆ [0,1] OR NULL

polar_ratio âˆˆ [0,1]

num_comments â‰¤ 200 (warn)

1ï¸âƒ£6ï¸âƒ£ LLM â€“ ××•×¤×¦×™×•× ×œ×™ ×‘×œ×‘×“

×œ× ×‘Ö¾critical path

enrichment × ×¤×¨×“

versioning ××œ×

×œ× ××©×¤×™×¢ ×¢×œ 7 ×”××“×“×™× ×”×“×˜×¨××™× ×™×¡×˜×™×™×




ğŸ“• Appendix A â€“ Concurrency, Staging & Algorithmic Specification

(×”×©×œ××” ××—×™×™×‘×ª ×œ-RFC ×”×¨××©×™)

Aï¸âƒ£ ××•×“×œ ××§×‘×™×œ×™×•×ª (Concurrency Model)
×¢×§×¨×•×Ÿ ×™×¡×•×“

×”××§×‘×™×œ×™×•×ª ×‘××¢×¨×›×ª ××•×’×‘×œ×ª ××š ×•×¨×§ ×œ×¨××ª ×”×›×ª×‘×” (article-level parallelism).

××™×Ÿ ××§×‘×™×œ×™×•×ª ×‘×ª×•×š ×›×ª×‘×”, ××™×Ÿ ××§×‘×™×œ×™×•×ª ×‘×ª×•×š ×—×œ×•×Ÿ, ×•××™×Ÿ ××§×‘×™×œ×™×•×ª ×‘×ª×•×š ×ª×’×•×‘×”.

×œ××” ×–×” ×§×¨×™×˜×™?

×©×•××¨ ×¢×œ ×“×˜×¨××™× ×™×–× ××•×—×œ×˜

××•× ×¢ race conditions

××•× ×¢ ×©×™× ×•×™ ×¡×“×¨ ×—×™×©×•×‘ ×©××©×¤×™×¢ ×¢×œ ×¤×œ×˜

×××¤×©×¨ reasoning ××œ×’×•×¨×™×ª××™ ×‘×¨×•×¨

××•×“×œ ×”×‘×™×¦×•×¢ ×‘×¤×•×¢×œ
×™×—×™×“×ª ×¢×‘×•×“×” (Atomic Unit)
ArticleJob(article_id)


×›×œ ArticleJob ××‘×¦×¢:

×¢×™×‘×•×“ ×›×ª×‘×” â†’ ×—×œ×•× ×•×ª

×¢×™×‘×•×“ ×ª×’×•×‘×•×ª â†’ ×¦×™×•× ×™ ×ª×’×•×‘×”

××’×¨×’×¦×™×” ×‘×¨××ª ×›×ª×‘×”

×›×ª×™×‘×” ×œ-staging (GCS)

Worker Pool

Airflow ××¤×¢×™×œ Worker Pool

×›×œ Worker:

××§×‘×œ article_id ××—×“

×¢×•×‘×“ ×¢×œ×™×• ××§×¦×” ×œ×§×¦×”

×œ× ××©×ª×£ state ×¢× Workers ××—×¨×™×

Big-O ×‘×”×§×©×¨ ××§×‘×™×œ×™×•×ª

××œ×’×•×¨×™×ª××™×ª:
O(sum(tokens_articles) + sum(tokens_comments))

××§×‘×™×œ×™×•×ª:

Speedup ×§×‘×•×¢ ×‘×œ×‘×“

××™×Ÿ ×©×™× ×•×™ ××¡×™××¤×˜×•×˜×™

×–×” ×—×©×•×‘ ×œ×¦×™×•×Ÿ ××§×“××™:

â€œParallelism improves wall-clock time but not asymptotic complexityâ€

Bï¸âƒ£ ×¤×™×¦×•×œ ×”×¤×™×™×¤×œ×™×™×Ÿ ×œ×©× ×™ ××¡×œ×•×œ×™× (Pipeline Split)
×œ××” ×—×™×™×‘×™× ×¤×™×¦×•×œ?

×›×™:

×›×ª×‘×•×ª ×”×Ÿ ×˜×§×¡×˜ ××‘× ×™

×ª×’×•×‘×•×ª ×”×Ÿ ××•×ª×•×ª ×§×”×œ

××—×–×•×¨ ×”×—×™×™× ×©×•× ×”

×”××œ×’×•×¨×™×ª××™× ×©×•× ×™×

×œ×›×Ÿ ×™×© ×©× ×™ ××¡×œ×•×œ×™× ×œ×•×’×™×™×, ×©××ª×›× ×¡×™× ×¨×§ ×‘×¨××ª ×”×›×ª×‘×”.

Cï¸âƒ£ Staging â€“ ×¤×™×¨×•×˜ ××œ× ×œ×¤×™ ×¤×™×™×¤×œ×™×™×Ÿ
C1ï¸âƒ£ Staging ×©×œ ×›×ª×‘×•×ª (Article â†’ Windows)
Input

article_with_comments.json
(×¨×§ ×©×“×” text ×¨×œ×•×•× ×˜×™ ×›××Ÿ)

××œ×’×•×¨×™×ª× ×—×™×©×•×‘ (Article Windows)
××‘× ×™ × ×ª×•× ×™×
counts: int[7]
active_categories: int
present_mask: int (bitmask)

×¤×¡××•×“×•-×§×•×“ (×¤×•×¨××œ×™)
for sentence in split_to_sentences(article_text):
    tokens = tokenize(sentence)

    if len(tokens) > 60:
        chunks = chunk(tokens, size=60)
    else:
        chunks = [tokens]

    for chunk in chunks:
        counts = [0,0,0,0,0,0,0]
        active = 0
        present_mask = 0

        for token in chunk:
            if token in word2category:
                c = word2category[token]
                if counts[c] == 0:
                    active += 1
                    present_mask |= (1 << c)
                counts[c] += 1

        cat_words = sum(counts)

        if cat_words > 0:
            dominance = max(counts) / cat_words
        else:
            dominance = NULL

        emit window_row

Output ×œ-Staging (Parquet)

×˜×‘×œ×” ×œ×•×’×™×ª: windows_features_staging

×©×“×•×ª:

article_id

sentence_idx

window_len

c1 â€¦ c7

active

present_mask

dominance

lexicon_version

pipeline_version

run_id

C2ï¸âƒ£ Staging ×©×œ ×ª×’×•×‘×•×ª (Comments â†’ Scores)
Input

article_with_comments.json
(×¨×§ ××¢×¨×š comments)

××œ×’×•×¨×™×ª× ×—×™×©×•×‘ (×ª×’×•×‘×•×ª)
×¤×¡××•×“×•-×§×•×“
for comment in comments:
    tokens = tokenize(comment.text)

    polar_count = count(tokens in comment_lexicon)
    comment_len = len(tokens)

    polar_ratio = polar_count / max(1, comment_len)
    like_weight = 1 + ln(1 + like_count)

    emit comment_row

Output ×œ-Staging (Parquet)

×˜×‘×œ×” ×œ×•×’×™×ª: comments_features_staging

×©×“×•×ª:

article_id

comment_id

comment_len

polar_count

polar_ratio

like_count

like_weight

comment_score

comment_lexicon_version

pipeline_version

run_id

C3ï¸âƒ£ Staging ×©×œ ××’×¨×’×¦×™×™×ª ×ª×’×•×‘×•×ª (Per Article)
×¤×¡××•×“×•-×§×•×“
scores = []
weights = []

for comment in article_comments:
    scores.append(comment_score)
    weights.append(like_weight)

audience_mean = weighted_mean(scores, weights)
audience_p85  = weighted_quantile(scores, weights, 0.85)

Output ×œ-Staging

×˜×‘×œ×”: article_comments_agg_staging

×©×“×•×ª:

article_id

num_comments

audience_mean

audience_p85

sum_like_weight

pipeline_version

run_id

Dï¸âƒ£ ×”×ª×›× ×¡×•×ª (Merge Point)

×©×œ×•×©×ª ×”-staging tables:

windows_features_staging

comments_features_staging

article_comments_agg_staging

× ×˜×¢× ×™× ×œ-BigQuery ×•×××•×–×’×™× (MERGE) ×œ×˜×‘×œ××•×ª ×”×¡×•×¤×™×•×ª.

â—ï¸××™×Ÿ Join ×‘×¤×™×™×¤×œ×™×™×Ÿ ×¢×¦××•.
â—ï¸×”×§×™×©×•×¨ ××ª×‘×¦×¢ ×¨×§ ×‘×××¦×¢×•×ª article_id ×‘-BQ.

Eï¸âƒ£ ×œ××” ×”××‘× ×” ×”×–×” × ×›×•×Ÿ ××—×§×¨×™×ª
1. ×”×¤×¨×“×ª ××•×ª×•×ª

×›×ª×‘×” = ××•×ª ×˜×§×¡×˜×•××œ×™

×ª×’×•×‘×•×ª = ××•×ª ×§×”×œ

×—×™×‘×•×¨ ×¨×§ ×‘×©××™×œ×ª×•×ª

2. ××œ×’×•×¨×™×ª××™× ×¤×©×•×˜×™× â†’ ××“×“×™× ×—×–×§×™×

××™×Ÿ ××•×“×œ×™× ×›×‘×“×™×

××™×Ÿ state ×—×‘×•×™

×›×œ ××¡×¤×¨ × ×™×ª×Ÿ ×œ×”×¡×‘×¨

3. × ×™×ª×Ÿ ×œ×”×¨×—×‘×”

××¤×©×¨ ×œ×”×•×¡×™×£ ×§×˜×’×•×¨×™×•×ª

××¤×©×¨ ×œ×”×•×¡×™×£ LLM

×‘×œ×™ ×œ×©×‘×•×¨ ×—×•×–×”